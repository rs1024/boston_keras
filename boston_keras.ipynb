{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data - features\n",
    "boston = load_boston()\n",
    "features = np.array(boston.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data - target\n",
    "target = np.array(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(features, target, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(379,)\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the data\n",
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "\n",
    "n_cols = Xtrain.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/10\n",
      "284/284 [==============================] - 1s - loss: 245.3551 - val_loss: 165.1611\n",
      "Epoch 2/10\n",
      "284/284 [==============================] - 0s - loss: 138.3780 - val_loss: 76.9877\n",
      "Epoch 3/10\n",
      "284/284 [==============================] - 0s - loss: 90.2867 - val_loss: 56.3536\n",
      "Epoch 4/10\n",
      "284/284 [==============================] - 0s - loss: 78.6577 - val_loss: 39.4966\n",
      "Epoch 5/10\n",
      "284/284 [==============================] - 0s - loss: 73.2594 - val_loss: 48.2749\n",
      "Epoch 6/10\n",
      "284/284 [==============================] - 0s - loss: 65.0691 - val_loss: 44.4548\n",
      "Epoch 7/10\n",
      "284/284 [==============================] - 0s - loss: 63.0472 - val_loss: 36.9471\n",
      "Epoch 8/10\n",
      "284/284 [==============================] - 0s - loss: 60.9671 - val_loss: 44.4506\n",
      "Epoch 9/10\n",
      "284/284 [==============================] - 0s - loss: 61.0204 - val_loss: 47.0270\n",
      "Epoch 10/10\n",
      "284/284 [==============================] - 0s - loss: 59.4982 - val_loss: 37.5303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224c9642400>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile and fit model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(Xtrain, ytrain, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.377005699694195"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ytest, model.predict(Xtest)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Try different learning rates\n",
    "\n",
    "Note that the SGD optimizer does not work well for continuous regression. Adam works best for regression (as shown above) while SGD works for classification (as shown in the Datacamp slides).\n",
    "\n",
    "Further, the using the SGD optimizer + a learning rate with a Sequential model where the activation functions for all layers is 'relu' leads to a loss of nan. I've changed the activation function of the last layer to be 'tanh' to get this exercise to work. 'softmax' and 'sigmoid' also work to a certain extent. However in reality, I wouldn't use the below structure for a regression network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_new_model():\n",
    "    # Create a basic model\n",
    "    n_cols = X.shape[1]\n",
    "    mod = Sequential()\n",
    "    mod.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "    mod.add(Dense(100, activation='relu'))\n",
    "    # Activation would be 'relu' normally, but is 'tanh' here to get the SGD learning rate to work\n",
    "    mod.add(Dense(100, activation='tanh'))\n",
    "    mod.add(Dense(1))\n",
    "    return(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing model with learning rate 0.000100\n",
      "Epoch 1/10\n",
      "506/506 [==============================] - 1s - loss: 340.2401     \n",
      "Epoch 2/10\n",
      "506/506 [==============================] - 0s - loss: 207.7320     \n",
      "Epoch 3/10\n",
      "506/506 [==============================] - 0s - loss: 148.3421     \n",
      "Epoch 4/10\n",
      "506/506 [==============================] - 0s - loss: 116.3528     \n",
      "Epoch 5/10\n",
      "506/506 [==============================] - 0s - loss: 99.1499      \n",
      "Epoch 6/10\n",
      "506/506 [==============================] - 0s - loss: 89.9163     \n",
      "Epoch 7/10\n",
      "506/506 [==============================] - 0s - loss: 83.6451     \n",
      "Epoch 8/10\n",
      "506/506 [==============================] - 0s - loss: 79.2458     \n",
      "Epoch 9/10\n",
      "506/506 [==============================] - 0s - loss: 76.3913     \n",
      "Epoch 10/10\n",
      "506/506 [==============================] - 0s - loss: 73.4567     \n",
      "\n",
      "Testing model with learning rate 0.001000\n",
      "Epoch 1/10\n",
      "506/506 [==============================] - 1s - loss: 173.6382     \n",
      "Epoch 2/10\n",
      "506/506 [==============================] - 0s - loss: 84.3926     \n",
      "Epoch 3/10\n",
      "506/506 [==============================] - 0s - loss: 85.1517     \n",
      "Epoch 4/10\n",
      "506/506 [==============================] - 0s - loss: 84.8899     \n",
      "Epoch 5/10\n",
      "506/506 [==============================] - 0s - loss: 84.7802     \n",
      "Epoch 6/10\n",
      "506/506 [==============================] - 0s - loss: 84.8007     \n",
      "Epoch 7/10\n",
      "506/506 [==============================] - 0s - loss: 85.0946     \n",
      "Epoch 8/10\n",
      "506/506 [==============================] - 0s - loss: 84.7051     \n",
      "Epoch 9/10\n",
      "506/506 [==============================] - 0s - loss: 85.0867     \n",
      "Epoch 10/10\n",
      "506/506 [==============================] - 0s - loss: 84.9922     \n",
      "\n",
      "Testing model with learning rate 0.010000\n",
      "Epoch 1/10\n",
      "506/506 [==============================] - 1s - loss: 204.1047     \n",
      "Epoch 2/10\n",
      "506/506 [==============================] - 0s - loss: 304.0399     \n",
      "Epoch 3/10\n",
      "506/506 [==============================] - 0s - loss: 1692.7160     \n",
      "Epoch 4/10\n",
      "506/506 [==============================] - 0s - loss: 2083.6595     \n",
      "Epoch 5/10\n",
      "506/506 [==============================] - 0s - loss: 2542.6099     \n",
      "Epoch 6/10\n",
      "506/506 [==============================] - 0s - loss: 2759.8344     \n",
      "Epoch 7/10\n",
      "506/506 [==============================] - 0s - loss: 2722.2172     \n",
      "Epoch 8/10\n",
      "506/506 [==============================] - 0s - loss: 4661.9573     \n",
      "Epoch 9/10\n",
      "506/506 [==============================] - 0s - loss: 6967.1556     \n",
      "Epoch 10/10\n",
      "506/506 [==============================] - 0s - loss: 17264.3744     \n",
      "\n",
      "Testing model with learning rate 0.100000\n",
      "Epoch 1/10\n",
      "506/506 [==============================] - 1s - loss: inf                               \n",
      "Epoch 2/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 3/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 4/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 5/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 6/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 7/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 8/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 9/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 10/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "\n",
      "Testing model with learning rate 0.500000\n",
      "Epoch 1/10\n",
      "506/506 [==============================] - 1s - loss: nan         \n",
      "Epoch 2/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 3/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 4/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 5/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 6/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 7/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 8/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 9/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 10/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "\n",
      "Testing model with learning rate 1.000000\n",
      "Epoch 1/10\n",
      "506/506 [==============================] - 1s - loss: nan         \n",
      "Epoch 2/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 3/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 4/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 5/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 6/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 7/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 8/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 9/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n",
      "Epoch 10/10\n",
      "506/506 [==============================] - 0s - loss: nan     \n"
     ]
    }
   ],
   "source": [
    "lr_to_test = [0.0001, 0.001, 0.01, 0.1, 0.5, 1]\n",
    "\n",
    "for lr in lr_to_test:\n",
    "    print('\\nTesting model with learning rate %f' % lr)\n",
    "    model2 = get_new_model()\n",
    "    sgd = SGD(lr=lr)\n",
    "    model2.compile(optimizer=sgd, loss='mean_squared_error')\n",
    "    model2.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(100, activation='relu'))\n",
    "model3.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/30\n",
      "284/284 [==============================] - 1s - loss: 212.8339 - val_loss: 124.8006\n",
      "Epoch 2/30\n",
      "284/284 [==============================] - 0s - loss: 89.7386 - val_loss: 80.4548\n",
      "Epoch 3/30\n",
      "284/284 [==============================] - 0s - loss: 78.8242 - val_loss: 102.7109\n",
      "Epoch 4/30\n",
      "284/284 [==============================] - 0s - loss: 79.7112 - val_loss: 61.9852\n",
      "Epoch 5/30\n",
      "284/284 [==============================] - 0s - loss: 65.8606 - val_loss: 42.9941\n",
      "Epoch 6/30\n",
      "284/284 [==============================] - 0s - loss: 75.0933 - val_loss: 59.1770\n",
      "Epoch 7/30\n",
      "284/284 [==============================] - 0s - loss: 69.2046 - val_loss: 37.7806\n",
      "Epoch 8/30\n",
      "284/284 [==============================] - 0s - loss: 61.4454 - val_loss: 36.7245\n",
      "Epoch 9/30\n",
      "284/284 [==============================] - 0s - loss: 57.9004 - val_loss: 40.3617\n",
      "Epoch 10/30\n",
      "284/284 [==============================] - 0s - loss: 57.1829 - val_loss: 35.7469\n",
      "Epoch 11/30\n",
      "284/284 [==============================] - 0s - loss: 54.7628 - val_loss: 41.1237\n",
      "Epoch 12/30\n",
      "284/284 [==============================] - 0s - loss: 58.9980 - val_loss: 89.0794\n",
      "Epoch 13/30\n",
      "284/284 [==============================] - 0s - loss: 76.5700 - val_loss: 32.1596\n",
      "Epoch 14/30\n",
      "284/284 [==============================] - 0s - loss: 64.8271 - val_loss: 31.8123\n",
      "Epoch 15/30\n",
      "284/284 [==============================] - 0s - loss: 58.3794 - val_loss: 32.0807\n",
      "Epoch 16/30\n",
      "284/284 [==============================] - 0s - loss: 55.9240 - val_loss: 41.4411\n",
      "Epoch 17/30\n",
      "284/284 [==============================] - 0s - loss: 60.6796 - val_loss: 34.2006\n",
      "Epoch 18/30\n",
      "284/284 [==============================] - 0s - loss: 61.0214 - val_loss: 32.5107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224d07e6e10>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model3.fit(Xtrain, ytrain, validation_split=0.25, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.616126585894719"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ytest, model3.predict(Xtest)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### More experimenting\n",
    "\n",
    "#### More layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(100, activation='relu'))\n",
    "model4.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/30\n",
      "284/284 [==============================] - 3s - loss: 260.8121 - val_loss: 77.5534\n",
      "Epoch 2/30\n",
      "284/284 [==============================] - 0s - loss: 97.3663 - val_loss: 61.3699\n",
      "Epoch 3/30\n",
      "284/284 [==============================] - 0s - loss: 73.7777 - val_loss: 60.0684\n",
      "Epoch 4/30\n",
      "284/284 [==============================] - 0s - loss: 69.1082 - val_loss: 42.7861\n",
      "Epoch 5/30\n",
      "284/284 [==============================] - 0s - loss: 68.0020 - val_loss: 46.5539\n",
      "Epoch 6/30\n",
      "284/284 [==============================] - 0s - loss: 69.6800 - val_loss: 39.7008\n",
      "Epoch 7/30\n",
      "284/284 [==============================] - 0s - loss: 72.9710 - val_loss: 57.8890\n",
      "Epoch 8/30\n",
      "284/284 [==============================] - 0s - loss: 65.8712 - val_loss: 56.7154\n",
      "Epoch 9/30\n",
      "284/284 [==============================] - 0s - loss: 72.0773 - val_loss: 39.3544\n",
      "Epoch 10/30\n",
      "284/284 [==============================] - 0s - loss: 66.2463 - val_loss: 39.5148\n",
      "Epoch 11/30\n",
      "284/284 [==============================] - 0s - loss: 63.0912 - val_loss: 38.5453\n",
      "Epoch 12/30\n",
      "284/284 [==============================] - 0s - loss: 61.1348 - val_loss: 38.8940\n",
      "Epoch 13/30\n",
      "284/284 [==============================] - 0s - loss: 59.5089 - val_loss: 37.7973\n",
      "Epoch 14/30\n",
      "284/284 [==============================] - 0s - loss: 59.5083 - val_loss: 41.6262\n",
      "Epoch 15/30\n",
      "284/284 [==============================] - 0s - loss: 59.6812 - val_loss: 37.6516\n",
      "Epoch 16/30\n",
      "284/284 [==============================] - 0s - loss: 60.1050 - val_loss: 41.5204\n",
      "Epoch 17/30\n",
      "284/284 [==============================] - 0s - loss: 58.8003 - val_loss: 46.3150\n",
      "Epoch 18/30\n",
      "284/284 [==============================] - 0s - loss: 59.7789 - val_loss: 48.3644: 55.65\n",
      "Epoch 19/30\n",
      "284/284 [==============================] - 0s - loss: 54.9868 - val_loss: 45.3999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224d0d76a20>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model4.fit(Xtrain, ytrain, validation_split=0.25, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.667983680161015"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ytest, model4.predict(Xtest)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### More nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(1000, activation='relu', input_shape=(n_cols,)))\n",
    "model5.add(Dense(1000, activation='relu'))\n",
    "model5.add(Dense(1000, activation='relu'))\n",
    "model5.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/30\n",
      "284/284 [==============================] - 2s - loss: 4195.4153 - val_loss: 515.9454\n",
      "Epoch 2/30\n",
      "284/284 [==============================] - 0s - loss: 244.5644 - val_loss: 175.9453\n",
      "Epoch 3/30\n",
      "284/284 [==============================] - 0s - loss: 95.2485 - val_loss: 48.8249\n",
      "Epoch 4/30\n",
      "284/284 [==============================] - 0s - loss: 70.1496 - val_loss: 53.5829\n",
      "Epoch 5/30\n",
      "284/284 [==============================] - 0s - loss: 67.7471 - val_loss: 44.1243\n",
      "Epoch 6/30\n",
      "284/284 [==============================] - 0s - loss: 67.1316 - val_loss: 47.3299\n",
      "Epoch 7/30\n",
      "284/284 [==============================] - 0s - loss: 63.5312 - val_loss: 45.8815\n",
      "Epoch 8/30\n",
      "284/284 [==============================] - 0s - loss: 62.7086 - val_loss: 41.8947\n",
      "Epoch 9/30\n",
      "284/284 [==============================] - 0s - loss: 61.5894 - val_loss: 37.7738\n",
      "Epoch 10/30\n",
      "284/284 [==============================] - 0s - loss: 65.2726 - val_loss: 42.4531\n",
      "Epoch 11/30\n",
      "284/284 [==============================] - 0s - loss: 63.1441 - val_loss: 44.0758\n",
      "Epoch 12/30\n",
      "284/284 [==============================] - 0s - loss: 60.3788 - val_loss: 51.7777\n",
      "Epoch 13/30\n",
      "284/284 [==============================] - 0s - loss: 60.5504 - val_loss: 36.4845\n",
      "Epoch 14/30\n",
      "284/284 [==============================] - 0s - loss: 57.8873 - val_loss: 42.1622\n",
      "Epoch 15/30\n",
      "284/284 [==============================] - 0s - loss: 58.0688 - val_loss: 39.4518\n",
      "Epoch 16/30\n",
      "284/284 [==============================] - 0s - loss: 56.0954 - val_loss: 37.4680\n",
      "Epoch 17/30\n",
      "284/284 [==============================] - 0s - loss: 54.7143 - val_loss: 32.5082\n",
      "Epoch 18/30\n",
      "284/284 [==============================] - 0s - loss: 58.8558 - val_loss: 42.2087\n",
      "Epoch 19/30\n",
      "284/284 [==============================] - 0s - loss: 59.5544 - val_loss: 42.2146\n",
      "Epoch 20/30\n",
      "284/284 [==============================] - 0s - loss: 54.9843 - val_loss: 32.1117\n",
      "Epoch 21/30\n",
      "284/284 [==============================] - 0s - loss: 57.9309 - val_loss: 44.0049\n",
      "Epoch 22/30\n",
      "284/284 [==============================] - 0s - loss: 53.6357 - val_loss: 28.8166\n",
      "Epoch 23/30\n",
      "284/284 [==============================] - 0s - loss: 50.7030 - val_loss: 41.1969\n",
      "Epoch 24/30\n",
      "284/284 [==============================] - 0s - loss: 50.2094 - val_loss: 50.5090\n",
      "Epoch 25/30\n",
      "284/284 [==============================] - 0s - loss: 48.7392 - val_loss: 24.9480\n",
      "Epoch 26/30\n",
      "284/284 [==============================] - 0s - loss: 47.5506 - val_loss: 25.9855\n",
      "Epoch 27/30\n",
      "284/284 [==============================] - 0s - loss: 43.9297 - val_loss: 26.1913\n",
      "Epoch 28/30\n",
      "284/284 [==============================] - 0s - loss: 40.6301 - val_loss: 27.3785\n",
      "Epoch 29/30\n",
      "284/284 [==============================] - 0s - loss: 38.8025 - val_loss: 25.3834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224d27fcb00>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model5.fit(Xtrain, ytrain, validation_split=0.25, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.810263704275414"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ytest, model5.predict(Xtest)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### More layers and nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Dense(1000, activation='relu', input_shape=(n_cols,)))\n",
    "model6.add(Dense(1000, activation='relu'))\n",
    "model6.add(Dense(1000, activation='relu'))\n",
    "model6.add(Dense(1000, activation='relu'))\n",
    "model6.add(Dense(1000, activation='relu'))\n",
    "model6.add(Dense(1000, activation='relu'))\n",
    "model6.add(Dense(1000, activation='relu'))\n",
    "model6.add(Dense(1000, activation='relu'))\n",
    "model6.add(Dense(1000, activation='relu'))\n",
    "model6.add(Dense(1000, activation='relu'))\n",
    "model6.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/30\n",
      "284/284 [==============================] - 2s - loss: 698.3341 - val_loss: 102.0227\n",
      "Epoch 2/30\n",
      "284/284 [==============================] - 0s - loss: 213.9721 - val_loss: 114.0644\n",
      "Epoch 3/30\n",
      "284/284 [==============================] - 0s - loss: 121.5692 - val_loss: 64.2238\n",
      "Epoch 4/30\n",
      "284/284 [==============================] - 0s - loss: 79.3414 - val_loss: 49.0877\n",
      "Epoch 5/30\n",
      "284/284 [==============================] - 0s - loss: 69.0817 - val_loss: 50.4760\n",
      "Epoch 6/30\n",
      "284/284 [==============================] - 0s - loss: 67.2803 - val_loss: 40.8885\n",
      "Epoch 7/30\n",
      "284/284 [==============================] - 0s - loss: 62.6686 - val_loss: 44.8597\n",
      "Epoch 8/30\n",
      "284/284 [==============================] - 0s - loss: 64.0916 - val_loss: 38.8311\n",
      "Epoch 9/30\n",
      "284/284 [==============================] - 0s - loss: 64.1506 - val_loss: 39.8364\n",
      "Epoch 10/30\n",
      "284/284 [==============================] - 0s - loss: 63.9410 - val_loss: 37.9141\n",
      "Epoch 11/30\n",
      "284/284 [==============================] - 0s - loss: 62.3681 - val_loss: 55.6581\n",
      "Epoch 12/30\n",
      "284/284 [==============================] - 0s - loss: 63.0229 - val_loss: 37.1258\n",
      "Epoch 13/30\n",
      "284/284 [==============================] - 0s - loss: 61.9645 - val_loss: 37.0199\n",
      "Epoch 14/30\n",
      "284/284 [==============================] - 0s - loss: 71.4344 - val_loss: 40.6993\n",
      "Epoch 15/30\n",
      "284/284 [==============================] - 0s - loss: 67.1008 - val_loss: 34.5961\n",
      "Epoch 16/30\n",
      "284/284 [==============================] - 0s - loss: 64.4572 - val_loss: 34.1763\n",
      "Epoch 17/30\n",
      "284/284 [==============================] - 0s - loss: 61.4328 - val_loss: 35.7712\n",
      "Epoch 18/30\n",
      "284/284 [==============================] - 0s - loss: 56.4044 - val_loss: 41.8095\n",
      "Epoch 19/30\n",
      "284/284 [==============================] - 0s - loss: 72.0991 - val_loss: 33.2817\n",
      "Epoch 20/30\n",
      "284/284 [==============================] - 0s - loss: 58.6020 - val_loss: 40.5709\n",
      "Epoch 21/30\n",
      "284/284 [==============================] - 0s - loss: 56.3063 - val_loss: 30.4477\n",
      "Epoch 22/30\n",
      "284/284 [==============================] - 0s - loss: 53.6716 - val_loss: 37.8200\n",
      "Epoch 23/30\n",
      "284/284 [==============================] - 0s - loss: 51.5681 - val_loss: 43.3869\n",
      "Epoch 24/30\n",
      "284/284 [==============================] - 0s - loss: 50.8093 - val_loss: 27.2953\n",
      "Epoch 25/30\n",
      "284/284 [==============================] - 0s - loss: 47.1341 - val_loss: 27.1667\n",
      "Epoch 26/30\n",
      "284/284 [==============================] - 0s - loss: 42.2677 - val_loss: 45.2681\n",
      "Epoch 27/30\n",
      "284/284 [==============================] - 0s - loss: 51.5958 - val_loss: 114.3310\n",
      "Epoch 28/30\n",
      "284/284 [==============================] - 0s - loss: 93.5804 - val_loss: 30.3155\n",
      "Epoch 29/30\n",
      "284/284 [==============================] - 0s - loss: 71.8419 - val_loss: 39.5257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224d03f6ac8>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model6.fit(Xtrain, ytrain, validation_split=0.25, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.420533055254552"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ytest, model6.predict(Xtest)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1,000 nodes, 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Dense(1000, activation='relu', input_shape=(n_cols,)))\n",
    "model7.add(Dense(1000, activation='relu'))\n",
    "model7.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284 samples, validate on 95 samples\n",
      "Epoch 1/30\n",
      "284/284 [==============================] - 1s - loss: 6515.7778 - val_loss: 4137.7961\n",
      "Epoch 2/30\n",
      "284/284 [==============================] - 0s - loss: 1961.2975 - val_loss: 881.8761\n",
      "Epoch 3/30\n",
      "284/284 [==============================] - 0s - loss: 460.8378 - val_loss: 142.7894\n",
      "Epoch 4/30\n",
      "284/284 [==============================] - 0s - loss: 198.9958 - val_loss: 68.8935\n",
      "Epoch 5/30\n",
      "284/284 [==============================] - 0s - loss: 129.1397 - val_loss: 81.3759\n",
      "Epoch 6/30\n",
      "284/284 [==============================] - 0s - loss: 113.0184 - val_loss: 109.7930\n",
      "Epoch 7/30\n",
      "284/284 [==============================] - 0s - loss: 75.3847 - val_loss: 41.9898\n",
      "Epoch 8/30\n",
      "284/284 [==============================] - 0s - loss: 72.8695 - val_loss: 41.6134\n",
      "Epoch 9/30\n",
      "284/284 [==============================] - 0s - loss: 72.8219 - val_loss: 48.8130\n",
      "Epoch 10/30\n",
      "284/284 [==============================] - 0s - loss: 64.7769 - val_loss: 44.6227\n",
      "Epoch 11/30\n",
      "284/284 [==============================] - 0s - loss: 62.2380 - val_loss: 42.6672\n",
      "Epoch 12/30\n",
      "284/284 [==============================] - 0s - loss: 61.8824 - val_loss: 37.8188\n",
      "Epoch 13/30\n",
      "284/284 [==============================] - 0s - loss: 63.3827 - val_loss: 37.1813\n",
      "Epoch 14/30\n",
      "284/284 [==============================] - 0s - loss: 62.2779 - val_loss: 47.0745\n",
      "Epoch 15/30\n",
      "284/284 [==============================] - 0s - loss: 58.6726 - val_loss: 35.5187\n",
      "Epoch 16/30\n",
      "284/284 [==============================] - 0s - loss: 62.6910 - val_loss: 36.3296\n",
      "Epoch 17/30\n",
      "284/284 [==============================] - 0s - loss: 60.6439 - val_loss: 36.8460\n",
      "Epoch 18/30\n",
      "284/284 [==============================] - 0s - loss: 61.4316 - val_loss: 34.7475\n",
      "Epoch 19/30\n",
      "284/284 [==============================] - 0s - loss: 58.7801 - val_loss: 37.1702\n",
      "Epoch 20/30\n",
      "284/284 [==============================] - 0s - loss: 55.7859 - val_loss: 41.9745\n",
      "Epoch 21/30\n",
      "284/284 [==============================] - 0s - loss: 56.5861 - val_loss: 42.0504\n",
      "Epoch 22/30\n",
      "284/284 [==============================] - 0s - loss: 56.3413 - val_loss: 33.6470\n",
      "Epoch 23/30\n",
      "284/284 [==============================] - 0s - loss: 53.9690 - val_loss: 35.5076\n",
      "Epoch 24/30\n",
      "284/284 [==============================] - 0s - loss: 51.7534 - val_loss: 37.9119\n",
      "Epoch 25/30\n",
      "284/284 [==============================] - 0s - loss: 51.9637 - val_loss: 37.1462\n",
      "Epoch 26/30\n",
      "284/284 [==============================] - 0s - loss: 51.6655 - val_loss: 31.2077\n",
      "Epoch 27/30\n",
      "284/284 [==============================] - 0s - loss: 52.6830 - val_loss: 30.6125\n",
      "Epoch 28/30\n",
      "284/284 [==============================] - 0s - loss: 50.2868 - val_loss: 32.2813\n",
      "Epoch 29/30\n",
      "284/284 [==============================] - 0s - loss: 50.8157 - val_loss: 32.9614\n",
      "Epoch 30/30\n",
      "284/284 [==============================] - 0s - loss: 47.8921 - val_loss: 32.4326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224d3a09c50>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model7.fit(Xtrain, ytrain, validation_split=0.25, epochs=30, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.323601616701026"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ytest, model7.predict(Xtest)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusions\n",
    "\n",
    "Based on the above, it seems that for this particular application, less layers but more nodes is optimal. Specifically, 3 layers with 1,000 nodes each produced the lowest MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
